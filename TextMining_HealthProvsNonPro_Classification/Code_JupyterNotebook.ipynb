{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "os.listdir('HealthProNonPro')\n",
    "\n",
    "def data2df (path, label):\n",
    "    file, text = [], []\n",
    "    for f in os.listdir(path):\n",
    "        file.append(f)\n",
    "        fhr = open (path+f, 'r', encoding='utf-8', errors='ignore')\n",
    "        t = fhr.read()\n",
    "        text.append(t)\n",
    "        fhr.close()\n",
    "    return (pd.DataFrame({'file': file, 'text': text, 'class':label}))\n",
    "\n",
    "dfPro = data2df('HealthProNonPro\\\\Pro\\\\',1) # Neg\n",
    "dfNonPro = data2df('HealthProNonPro\\\\NonPro\\\\',0) # Pos\n",
    "df = pd.concat([dfPro, dfNonPro], axis=0)\n",
    "df.sample(frac=0.0005)\n",
    "\n",
    "# import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "#Xtrain,Xtest,ytrain,ytest = train_test_split(df['text'], df['class'], test_size=0.3)\n",
    "Xtrain,Xtest,ytrain,ytest = train_test_split(df['text'], df['class'], test_size=0.3)\n",
    "\n",
    "#custom preprocessor\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "def preprocess(text):\n",
    "    # replace one or more white-space characters with a space\n",
    "    regex = re.compile(r\"\\s+\")                               \n",
    "    text = regex.sub(' ', text)    \n",
    "    # lower case\n",
    "    text = text.lower()          \n",
    "    # remove digits and punctuation\n",
    "    regex = re.compile(r\"[%s%s]\" % (string.punctuation, string.digits))\n",
    "    text = regex.sub(' ', text)           \n",
    "    # remove stop words\n",
    "    sw = stopwords.words('english')\n",
    "    text = text.split()                                              \n",
    "    text = ' '.join([w for w in text if w not in sw]) \n",
    "    # remove short words\n",
    "    ' '.join([w for w in text.split() if len(w) >= 2])\n",
    "    # lemmatize\n",
    "    text = ' '.join([(WordNetLemmatizer()).lemmatize(w) for w in text.split()]) \n",
    "    return text\n",
    "\n",
    "#import pipeline, tfidf, naive_bayes, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#create Pipeline\n",
    "clf=Pipeline(steps=[('pp', TfidfVectorizer(preprocessor=preprocess,\n",
    "                                          use_idf=True, smooth_idf=True,\n",
    "                                           min_df=1, max_df=1.0,\n",
    "                                           max_features=None, ngram_range=(1, 1))),\n",
    "                    ('mdl', MultinomialNB())])\n",
    "\n",
    "#create parameters\n",
    "parameters = {'pp__norm':('l1', 'l2', None), 'mdl__alpha':[0.01, 0.1, 0.2, 0.5, 1]}\n",
    "#create GridSearch\n",
    "grid_search = GridSearchCV(clf, parameters, cv=5, return_train_score=False)\n",
    "#fit GridSearch\n",
    "grid_search.fit(Xtrain, ytrain)\n",
    "\n",
    "#predict using best model\n",
    "ypred = grid_search.best_estimator_.predict(Xtest)\n",
    "# print scores\n",
    "from sklearn import metrics\n",
    "print (metrics.accuracy_score(ytest, ypred))\n",
    "print (metrics.confusion_matrix(ytest, ypred))\n",
    "print (metrics.classification_report(ytest, ypred))\n",
    "\n",
    "#print GridSerach best parameters\n",
    "#print(grid_search.best_estimator_, \"\\n\")\n",
    "#print(grid_search.best_params_, \"\\n\")\n",
    "#print(grid_search.best_score_, \"\\n\")\n",
    "#print(grid_search.cv_results_, \"\\n\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
